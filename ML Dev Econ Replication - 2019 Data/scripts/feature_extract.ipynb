{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the images marked as valid per cluster, we pass them through the CNN and extract their feature vectors. the results are stored at a per-country basis. For example, all Malawi feature extractions will go into results/malawi_2019/cnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '..'\n",
    "COUNTRIES_DIR = os.path.join(BASE_DIR, 'data', 'countries')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "CNN_TRAIN_IMAGE_DIR = os.path.join(BASE_DIR, 'data', 'cnn_images')\n",
    "CNN_DIR = os.path.join(BASE_DIR, 'models', 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create results directories for each country if they don't exist\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "for country in ['malawi_2019', 'ethiopia_2019', 'nigeria_2019']:\n",
    "    os.makedirs(os.path.join(RESULTS_DIR, country), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extract with CNN\n",
    "If you have run this step before, you can skip it and run the commented out code in the next section to quick-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.read_csv(os.path.join(PROCESSED_DIR, 'image_download_actual.csv')) #those are the 33k images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.0935306549072_35.20822373164363_-17.093530...</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.208224</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.07855873350521_35.20822373164363_-17.09353...</td>\n",
       "      <td>-17.078559</td>\n",
       "      <td>35.208224</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.123474497711186_35.22319565304562_-17.0935...</td>\n",
       "      <td>-17.123474</td>\n",
       "      <td>35.223196</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.138446419113176_35.23816757444761_-17.0935...</td>\n",
       "      <td>-17.138446</td>\n",
       "      <td>35.238168</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.063586812103217_35.23816757444761_-17.0935...</td>\n",
       "      <td>-17.063587</td>\n",
       "      <td>35.238168</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  -17.0935306549072_35.20822373164363_-17.093530... -17.093531  35.208224   \n",
       "1  -17.07855873350521_35.20822373164363_-17.09353... -17.078559  35.208224   \n",
       "2  -17.123474497711186_35.22319565304562_-17.0935... -17.123474  35.223196   \n",
       "3  -17.138446419113176_35.23816757444761_-17.0935... -17.138446  35.238168   \n",
       "4  -17.063586812103217_35.23816757444761_-17.0935... -17.063587  35.238168   \n",
       "\n",
       "   cluster_lat  cluster_lon   cons_pc  nightlights country  nightlights_bin  \\\n",
       "0   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "1   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "2   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "3   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "4   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "\n",
       "   is_train  \n",
       "0      True  \n",
       "1      True  \n",
       "2     False  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images.head() #variable with training, validation metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as backend\n"
     ]
    }
   ],
   "source": [
    "#Set up the device for PyTorch (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} as backend')\n",
    "model = torch.load(CNN_DIR, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the classifier part of the CNN model\n",
    "#CNN model typically has two main parts:\n",
    "\n",
    "#Feature Extractor: This is usually a series of convolutional layers that process the input images \n",
    "#and extract features. These layers apply filters to the input to create feature maps that \n",
    "#represent various aspects of the input data.\n",
    "\n",
    "#Classifier: After the feature extractor, the model includes a classifier, which is typically \n",
    "#made up of fully connected layers (also known as linear layers in PyTorch). The classifier's job \n",
    "#is to take the features extracted by the convolutional layers and use them to classify the input \n",
    "#image into various categories (e.g., different types of objects in an image recognition task).\"\"\"\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the first 4 layers for feature extraction\n",
    "model.classifier = model.classifier[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0eae846e96404898800ace31e1294f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1780d19dc61b4895a04586a342c3bdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380b19a5d1cd4e8f90e55cb7c0be770a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Define image transformations and create a custom dataset class for image loading\n",
    "transformer = transforms.Compose([#takes a list of transformation commands, applies them sequentially to an image. \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# custom dataset for fast image loading and processing\n",
    "# does not follow the usual style of folder -> folder for each class -> image\n",
    "# we just want one folder with images\n",
    "class ForwardPassDataset(torch.utils.data.Dataset):\n",
    "    #forward pass just means running data through the CNN\n",
    "    def __init__(self, image_dir, transformer):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(self.image_dir)\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_list[index]\n",
    "\n",
    "        # Load image\n",
    "        X = self.filename_to_im_tensor(self.image_dir + '/' + image_name)\n",
    "        \n",
    "        # dataloaders need to return a label, but for the forward pass we don't really care\n",
    "        return X, -1\n",
    "    \n",
    "    def filename_to_im_tensor(self, file):\n",
    "        im = plt.imread(file)[:,:,:3]\n",
    "        im = self.transformer(im)\n",
    "        return im\n",
    "\n",
    "model.eval() # for evaluating, instead of training the model. \n",
    "classes = [0, 1, 2]\n",
    "# shape of final array will be (num_validation_images, 4096)\n",
    "# we also want to record the image each index represents\n",
    "feats = np.zeros(((~df_images['is_train']).sum(), 4096))\n",
    "image_order = []\n",
    "i = 0\n",
    "for c in classes:\n",
    "    # use the validation images to do the forward pass\n",
    "    dataset = ForwardPassDataset(os.path.join(CNN_TRAIN_IMAGE_DIR, 'valid', str(c)), transformer)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    image_order += dataset.image_list\n",
    "    # forward pass for this class\n",
    "    for inputs, _ in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        feats[i:i+len(inputs),:] = outputs.cpu().detach().numpy()\n",
    "        i += len(inputs)\n",
    "        \n",
    "transformer = transforms.Compose([#takes a list of transformation commands, applies them sequentially to an image. \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4096325 ,  0.18340945,  0.66169846, ..., -0.67364454,\n",
       "        -0.27376688, -0.28155813],\n",
       "       [ 0.35640758,  0.06036946, -0.51295668, ..., -0.3266423 ,\n",
       "        -0.49054784, -0.00386778],\n",
       "       [ 0.04689836,  0.50569928, -0.59484124, ..., -0.21110877,\n",
       "        -0.02411379,  0.34765425],\n",
       "       ...,\n",
       "       [ 0.02955244,  0.44402122, -0.50215864, ...,  0.42083105,\n",
       "         0.81993848, -0.56816518],\n",
       "       [-0.54984337,  0.45200229, -0.80329543, ..., -0.66747063,\n",
       "        -0.10088408,  0.05845577],\n",
       "       [-0.54904073,  0.41596875, -0.91849011, ...,  0.63263136,\n",
       "         0.71722877, -1.40478349]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.028112114259333_33.44129297258391_-9.99917...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.034778406662008_33.93980560787962_-10.0497...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.049750328064_33.99969329348758_-10.0497503...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.0754804611206_33.345972449905325_-10.07548...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.094666092269977_33.99969329348758_-10.0497...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  feat_index\n",
       "0  -10.028112114259333_33.44129297258391_-9.99917...           0\n",
       "1  -10.034778406662008_33.93980560787962_-10.0497...           1\n",
       "2  -10.049750328064_33.99969329348758_-10.0497503...           2\n",
       "3  -10.0754804611206_33.345972449905325_-10.07548...           3\n",
       "4  -10.094666092269977_33.99969329348758_-10.0497...           4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass_df = pd.DataFrame.from_dict({'image_name': image_order, 'feat_index': np.arange(len(image_order))})\n",
    "forward_pass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumption = pd.merge(left=df_images, right=forward_pass_df, on='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have we maintained all validation images?\n",
    "assert len(df_consumption) == (~df_images['is_train']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.123474497711186_35.22319565304562_-17.0935...</td>\n",
       "      <td>-17.123474</td>\n",
       "      <td>35.223196</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.138446419113176_35.268111417251596_-17.093...</td>\n",
       "      <td>-17.138446</td>\n",
       "      <td>35.268111</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.063586812103217_35.29805526005558_-17.0935...</td>\n",
       "      <td>-17.063587</td>\n",
       "      <td>35.298055</td>\n",
       "      <td>-17.093531</td>\n",
       "      <td>35.253139</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.110595314376873_35.13684616574092_-17.0656...</td>\n",
       "      <td>-17.110595</td>\n",
       "      <td>35.136846</td>\n",
       "      <td>-17.065680</td>\n",
       "      <td>35.166790</td>\n",
       "      <td>1.834210</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.0656795501709_35.13684616574092_-17.065679...</td>\n",
       "      <td>-17.065680</td>\n",
       "      <td>35.136846</td>\n",
       "      <td>-17.065680</td>\n",
       "      <td>35.166790</td>\n",
       "      <td>1.834210</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  -17.123474497711186_35.22319565304562_-17.0935... -17.123474  35.223196   \n",
       "1  -17.138446419113176_35.268111417251596_-17.093... -17.138446  35.268111   \n",
       "2  -17.063586812103217_35.29805526005558_-17.0935... -17.063587  35.298055   \n",
       "3  -17.110595314376873_35.13684616574092_-17.0656... -17.110595  35.136846   \n",
       "4  -17.0656795501709_35.13684616574092_-17.065679... -17.065680  35.136846   \n",
       "\n",
       "   cluster_lat  cluster_lon   cons_pc  nightlights country  nightlights_bin  \\\n",
       "0   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "1   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "2   -17.093531    35.253139  1.994561     0.034344      mw                0   \n",
       "3   -17.065680    35.166790  1.834210     0.001391      mw                0   \n",
       "4   -17.065680    35.166790  1.834210     0.001391      mw                0   \n",
       "\n",
       "   is_train  feat_index  \n",
       "0     False        1302  \n",
       "1     False        1303  \n",
       "2     False        1298  \n",
       "3     False        1300  \n",
       "4     False        1299  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumption.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Features\n",
    "For each country, we aggregate the image features per cluster and save them to results/country/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_abbrv = ['mw', 'eth', 'ng']\n",
    "country_dir = ['malawi_2019', 'ethiopia_2019', 'nigeria_2019']\n",
    "\n",
    "for ca, cd in zip(country_abbrv, country_dir):\n",
    "    df_c = df_consumption[df_consumption['country'] == ca]\n",
    "    group = df_c.groupby(['cluster_lat', 'cluster_lon'])\n",
    "    x = np.zeros((len(group), 4096))\n",
    "    cluster_list = [] # the corresponding clusters (lat, lon) to the x aggregate feature array\n",
    "    for i, g in enumerate(group):\n",
    "        lat, lon = g[0]\n",
    "        im_sub = df_consumption[(df_consumption['cluster_lat'] == lat) & (df_consumption['cluster_lon'] == lon)].reset_index(drop=True)\n",
    "        agg_feats = np.zeros((len(im_sub), 4096))\n",
    "        for j, d in im_sub.iterrows():\n",
    "            agg_feats[j,:] = feats[d.feat_index]\n",
    "        agg_feats = agg_feats.mean(axis=0) # averages the features across all images in the cluster\n",
    "\n",
    "        x[i,:] = agg_feats\n",
    "        cluster_list.append([lat, lon])\n",
    "    # save to the correct directory\n",
    "    save_dir = os.path.join(RESULTS_DIR, cd, 'cnn')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    np.save(os.path.join(save_dir, 'cluster_feats.npy'), x)\n",
    "    pickle.dump(cluster_list, open(os.path.join(save_dir, 'cluster_order.pkl'), 'wb')) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "nightlight",
   "language": "python",
   "name": "nightlight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
